"""
Precomputed feature (.npy) based frame-level inference for violence detection.
- Looks for features in: hf_npy/{video_name}.npy
- Assumes features are per 2s window with 1s stride (same as original pipeline)
- Output: frame-level CSV (frame, violence)
"""

import os
import math
import torch
import numpy as np
import pandas as pd
from tqdm import tqdm
from model import Model
from pytorchvideo.data.encoded_video import EncodedVideo  # duration/fpsë§Œ ì¡°íšŒ

# ===== CONFIG =====
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model_path = "saved_models/888tiny_finetuned_no_sw_llava_data.pkl"

video_root_folder = "hf-violence/video"     # ì²˜ë¦¬í•  ì˜ìƒ í´ë” (duration/fps ì¡°íšŒìš©)
frame_score_folder = "hf-violence/predict-ft-llava"  # í”„ë ˆì„ ë‹¨ìœ„ ì ìˆ˜ CSV ì €ì¥ í´ë”
feat_root_folder = "hf_npy"                  # ë¯¸ë¦¬ ì¶”ì¶œí•´ë‘” íŠ¹ì§• í´ë”
os.makedirs(frame_score_folder, exist_ok=True)

threshold = 0.5
valid_exts = [".mp4", ".avi"]

# ===== ì›ë˜ íŒŒì´í”„ë¼ì¸ì˜ ì‹œê°„ íŒŒë¼ë¯¸í„° ì¬ì‚¬ìš© =====
transform_params = {
    "num_frames": 15,
    "sampling_rate": 4,
    "side_size": 320,
    "crop_size": 320,
    "frames_per_second": 30,
}
# 2ì´ˆ ìœˆë„ìš°, 1ì´ˆ ìŠ¤íŠ¸ë¼ì´ë“œ(ì› ì½”ë“œì™€ ë™ì¼)
def get_window_stride_seconds():
    fps = transform_params["frames_per_second"]
    window_sec = (transform_params["num_frames"] * transform_params["sampling_rate"]) / fps
    stride_sec = 1.0
    return window_sec, stride_sec, fps

# ===== ì´ìƒ íŒë‹¨ í•¨ìˆ˜ (ê·¸ëŒ€ë¡œ ì‚¬ìš©) =====
@torch.no_grad()
def predict_anomaly(feature_4d, model):
    """
    feature_4d: torch.Tensor, shape (C,T,H,W)
    model: returns (score, aux)
    """
    score, _ = model(feature_4d.unsqueeze(0).to(device))  # (1,C,T,H,W)
    return torch.sigmoid(score).item()

# ===== NPY ê¸°ë°˜ í”„ë ˆì„ ë ˆë²¨ ì¸í¼ëŸ°ìŠ¤ =====
def frame_level_inference_from_npy(video_path, feature_npy_path, model, threshold=0.5):
    # ë¹„ë””ì˜¤ ê¸¸ì´/í”„ë ˆì„ìˆ˜ íŒŒì•…(í”„ë ˆì„ ë¼ë²¨ ê¸¸ì´ ì‚°ì¶œìš©) - ë””ì½”ë”©/ì „ì²˜ë¦¬ëŠ” í•˜ì§€ ì•ŠìŒ
    video = EncodedVideo.from_path(video_path)
    duration = float(video.duration)

    window_sec, stride_sec, fps = get_window_stride_seconds()

    num_frames = int(duration * fps)
    frame_scores = np.zeros(num_frames, dtype=np.float32)
    frame_counts = np.zeros(num_frames, dtype=np.float32)

    # ì €ì¥ëœ íŠ¹ì§• ë¶ˆëŸ¬ì˜¤ê¸°
    npy = np.load(feature_npy_path, allow_pickle=False)
    # ê¸°ëŒ€ í˜•íƒœ: (N, C, T, H, W) ë˜ëŠ” (C, T, H, W) 1ê°œ ìœˆë„ìš°
    if npy.ndim == 4:
        npy = npy[None, ...]  # (1, C, T, H, W)
    assert npy.ndim == 5, f"Expected 4D/5D feature, got shape {npy.shape}"

    total_steps = npy.shape[0]

    for step in tqdm(range(total_steps), desc="  Processing feature windows", leave=False, ncols=80):
        feature = torch.from_numpy(npy[step]).float().to(device)  # (C,T,H,W)
        score = predict_anomaly(feature, model)

        start = step * stride_sec
        end = start + window_sec

        # í”„ë ˆì„ ë‹¨ìœ„ ëˆ„ì (ì› ì½”ë“œì™€ ë™ì¼ ë¡œì§)
        start_frame = int(start * fps)
        end_frame = min(int(end * fps), num_frames)
        if start_frame < end_frame:  # ì•ˆì „ì¥ì¹˜
            frame_scores[start_frame:end_frame] += score
            frame_counts[start_frame:end_frame] += 1

    # í‰ê·  í™•ë¥  â†’ ì´ìƒ ì—¬ë¶€ ë³€í™˜(ì› ì½”ë“œì™€ ë™ì¼)
    frame_scores /= np.maximum(frame_counts, 1)
    frame_labels = (frame_scores >= threshold).astype(np.int32)
    return frame_labels

# ===== MAIN =====
if __name__ == "__main__":
    model = Model(ff_mult=1, dims=(32, 32), depths=(1, 1)).to(device)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()

    video_files = [
        fname for fname in os.listdir(video_root_folder)
        if os.path.splitext(fname)[-1].lower() in valid_exts
    ]

    for idx, fname in enumerate(video_files, start=1):
        print(f"\n[{idx}/{len(video_files)}] Processing {fname}")
        video_path = os.path.join(video_root_folder, fname)
        video_name = os.path.splitext(fname)[0]
        feat_path = os.path.join(feat_root_folder, f"{video_name}.npy")

        if not os.path.isfile(feat_path):
            print(f"  âš ï¸ Feature not found: {feat_path} (skip)")
            continue

        try:
            frame_labels = frame_level_inference_from_npy(
                video_path, feat_path, model, threshold=threshold
            )

            # ===== í”„ë ˆì„ ë‹¨ìœ„ CSV ì €ì¥ =====
            save_path = os.path.join(frame_score_folder, f"{video_name}.csv")
            pd.DataFrame({
                "frame": np.arange(len(frame_labels)),
                "violence": frame_labels
            }).to_csv(save_path, index=False)
            print(f"  âœ… Saved: {save_path}")

        except Exception as e:
            print(f"  ğŸš¨ Error processing {fname}: {e}")
            continue

    print(f"\nâœ… All frame-level CSVs saved in folder: {frame_score_folder}")
